{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/univerself/igames/blob/main/text/fin_project/sentiment%20c6w3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSMzk9XqWC2b"
      },
      "source": [
        "# Анализ тональности отзывов на фильмы: cоревнование по сентимент-анализу"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc0yTh1aWC2i"
      },
      "source": [
        "## Введение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZACwezMY2jt"
      },
      "source": [
        "### Постановка задачи"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt3G_7zYWC2l"
      },
      "source": [
        "В этом задании вам нужно воспользоваться опытом предыдущих недель, чтобы побить бейзлайн в соревновании по сентимент-анализу отзывов на товары на Kaggle Inclass:\n",
        "\n",
        "https://www.kaggle.com/c/simplesentiment\n",
        "\n",
        "В этом соревновании вам предстоит прогнозировать по тексту отзыва его тональность: 1 - позитивная, 0 - негативная. В качестве метрики качества используется accuracy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJawCA7UZFu6"
      },
      "source": [
        "### План выполнения"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы проверим следующие модели:\n",
        "\n",
        "1. базовый для многих задач обработки естественного языка наивный байесовский классификатор;\n",
        "2. линейный классификатор на логистической регрессии, использующий предобработанный текст;\n",
        "3. линейный классификатор с использованием векторных представлений слов;\n",
        "4. дообученная нейросетевая модель-трансформер на основе BERT."
      ],
      "metadata": {
        "id": "9AAsBn3YvSPO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyidZtF7s9Qw"
      },
      "source": [
        "### Условия воспроизведения\n",
        "\n",
        "Использованы следующие версии библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7gdQqQU8Uhz",
        "outputId": "229b8fb2-3220-4e9e-cb46-0a23512ab01e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.5-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 70.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.27)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.0-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 9.7 MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.8.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.3.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 72.3 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.4.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 76.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=a04b6f47901b0fbef870a50db9bb907528113d53fdd9dd23c975a85e1fa7d638\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.6 alembic-1.7.5 autopage-0.4.0 cliff-3.10.0 cmaes-0.8.2 cmd2-2.3.3 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.0 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ],
      "source": [
        "#Если не установлен пакет для подбора гиперпараметров Optuna, раскомментируйте подходящую строку и выполните ячейку\n",
        "\n",
        "!pip install optuna\n",
        "# !conda install -c conda-forge optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11-vwtMXvDuI",
        "outputId": "e32e12e0-3e16-4b5d-a55c-44f1e5fc4e24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.2.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.13)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.1)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.8.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Collecting en-core-web-sm==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.9 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.2.0) (3.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.19.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "# Если не установлен пакет для работы с естественным языком spacy, можно установить через pip:\n",
        "!pip install -U spacy\n",
        "# или Anaconda  (может задать вопрос, так что лучше открыть терминал):\n",
        "# conda install -c conda-forge spacy\n",
        "# Потом поставить языковую модель английского языка.\n",
        "!python -m spacy download en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X0DeKa1ZE9c",
        "outputId": "6fcf2b5b-09af-4458-ceb7-39af9b6ff0cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy 1.19.5 Pandas 1.1.5 Sci-Kit Learn 1.0.1 NLTK 3.2.5 SpaCy 2.2.4 Optuna 2.10.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import nltk\n",
        "import spacy\n",
        "import optuna\n",
        "\n",
        "print(\n",
        "    \"NumPy\", np.__version__,\n",
        "    \"Pandas\", pd.__version__,\n",
        "    \"Sci-Kit Learn\", sklearn.__version__,\n",
        "    \"NLTK\", nltk.__version__,\n",
        "    \"SpaCy\", spacy.__version__,\n",
        "    \"Optuna\", optuna.__version__\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOWMolvmzHa7"
      },
      "source": [
        "## Сбор и первичный анализ данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": "OK"
            }
          }
        },
        "id": "fc1q6mJEbI4p",
        "outputId": "75c23c18-58bb-4646-e219-19e5893613dc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-31ed5f4b-af8a-4141-9701-018b81dfc1b5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-31ed5f4b-af8a-4141-9701-018b81dfc1b5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "ref                                                         title                                              size  lastUpdated          downloadCount  \n",
            "----------------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  \n",
            "gpreda/reddit-vaccine-myths                                 Reddit Vaccine Myths                              237KB  2021-12-12 11:59:54          18549  \n",
            "crowww/a-large-scale-fish-dataset                           A Large Scale Fish Dataset                          3GB  2021-04-28 17:03:01          11216  \n",
            "imsparsh/musicnet-dataset                                   MusicNet Dataset                                   22GB  2021-02-18 14:12:19           5752  \n",
            "dhruvildave/wikibooks-dataset                               Wikibooks Dataset                                   2GB  2021-10-22 10:48:21           3956  \n",
            "nickuzmenkov/nih-chest-xrays-tfrecords                      NIH Chest X-rays TFRecords                         11GB  2021-03-09 04:49:23           1987  \n",
            "promptcloud/careerbuilder-job-listing-2020                  Careerbuilder Job Listing 2020                     42MB  2021-03-05 06:59:52           3080  \n",
            "mathurinache/twitter-edge-nodes                             Twitter Edge Nodes                                342MB  2021-03-08 06:43:04           1486  \n",
            "fatiimaezzahra/famous-iconic-women                          Famous Iconic Women                               838MB  2021-02-28 14:56:00           2175  \n",
            "mathurinache/the-lj-speech-dataset                          The LJ Speech Dataset                               3GB  2021-02-15 09:19:54            604  \n",
            "coloradokb/dandelionimages                                  DandelionImages                                     4GB  2021-02-19 20:03:47           1171  \n",
            "alsgroup/end-als                                            End ALS Kaggle Challenge                           12GB  2021-04-08 12:16:37           1214  \n",
            "simiotic/github-code-snippets                               GitHub Code Snippets                                7GB  2021-03-03 11:34:39            571  \n",
            "imsparsh/accentdb-core-extended                             AccentDB - Core & Extended                          6GB  2021-02-17 14:22:54            210  \n",
            "stuartjames/lights                                          LightS: Light Specularity Dataset                  18GB  2021-02-18 14:32:26            271  \n",
            "nickuzmenkov/ranzcr-clip-kfold-tfrecords                    RANZCR CLiP KFold TFRecords                         2GB  2021-02-21 13:29:51            177  \n",
            "landrykezebou/lvzhdr-tone-mapping-benchmark-dataset-tmonet  LVZ-HDR Tone Mapping Benchmark Dataset (TMO-Net)   24GB  2021-03-01 05:03:40            277  \n",
            "datasnaek/youtube-new                                       Trending YouTube Video Statistics                 201MB  2019-06-03 00:56:47         162940  \n",
            "zynicide/wine-reviews                                       Wine Reviews                                       51MB  2017-11-27 17:08:04         152221  \n",
            "residentmario/ramen-ratings                                 Ramen Ratings                                      40KB  2018-01-11 16:04:39          31694  \n",
            "datasnaek/chess                                             Chess Game Dataset (Lichess)                        3MB  2017-09-04 03:09:09          26818  \n"
          ]
        }
      ],
      "source": [
        "# Подключение API Kaggle. Ячейку можно не выполнять, если данные уже скачаны и размещены в папке с блокнотом\n",
        "# !pip install -q kaggle # Раскомментируйте, если API Kaggle не установлен\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTAfRu8-cgdS",
        "outputId": "d68087d3-d344-420d-9260-af20ff078059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading products_sentiment_sample_submission.csv to /content\n",
            "  0% 0.00/2.83k [00:00<?, ?B/s]\n",
            "100% 2.83k/2.83k [00:00<00:00, 5.44MB/s]\n",
            "Downloading products_sentiment_test.tsv to /content\n",
            "  0% 0.00/50.9k [00:00<?, ?B/s]\n",
            "100% 50.9k/50.9k [00:00<00:00, 53.6MB/s]\n",
            "Downloading products_sentiment_train.tsv to /content\n",
            "  0% 0.00/193k [00:00<?, ?B/s]\n",
            "100% 193k/193k [00:00<00:00, 57.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Непосредственно загружаем набор данных. Ячейку можно не выполнять, если данные уже скачаны и размещены в папке с блокнотом\n",
        "!kaggle competitions download -c simplesentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzoqphvtWC2v",
        "outputId": "39ef4a31-a577-409e-e322-c141c3447cfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество размеченных отзывов - 2000, в т.ч. позитивных  1274 (63.7%)\n",
            "Количество тестовых отзывов - 500\n"
          ]
        }
      ],
      "source": [
        "# Загружаем данные\n",
        "df_marked = pd.read_csv('products_sentiment_train.tsv', sep = '\\t', header = None, names = ['text', 'y'])\n",
        "print (\"Количество размеченных отзывов - %d, в т.ч. позитивных  %d (%0.1f%%)\" % \n",
        "       (df_marked.shape[0], df_marked.y.sum(), 100.*df_marked.y.mean()))\n",
        "\n",
        "df_answer = pd.read_csv('products_sentiment_test.tsv', sep = '\\t')\n",
        "print (\"Количество тестовых отзывов - %d\" % (df_answer.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJzgr6BOWC2x"
      },
      "source": [
        "При обучении и кросс-валидации нужно будет учесть, что классы несбалансированы.\n",
        "\n",
        "Посмотрим на несколько отзывов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "4eoZpAVwWC2x",
        "outputId": "485ea81c-18b5-4aab-9cb0-0c9db9a73834"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1c6854d7-37c5-4613-b614-1638b3c432f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2 . take around 10,000 640x480 pictures .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i downloaded a trial version of computer associates ez firewall and antivirus and fell in love with a computer security system all over again .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the wrt54g plus the hga7t is a perfect solution if you need wireless coverage in a wider area or for a hard-walled house as was my case .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i dont especially like how music files are unstructured ; basically they are just dumped into one folder with no organization , like you might have in windows explorer folders and subfolders .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i was using the cheapie pail ... and it worked ok until the opening device fell apart .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c6854d7-37c5-4613-b614-1638b3c432f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1c6854d7-37c5-4613-b614-1638b3c432f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1c6854d7-37c5-4613-b614-1638b3c432f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                                                                                                                                                               text  y\n",
              "0                                                                                                                                                         2 . take around 10,000 640x480 pictures .  1\n",
              "1                                                   i downloaded a trial version of computer associates ez firewall and antivirus and fell in love with a computer security system all over again .  1\n",
              "2                                                         the wrt54g plus the hga7t is a perfect solution if you need wireless coverage in a wider area or for a hard-walled house as was my case .  1\n",
              "3  i dont especially like how music files are unstructured ; basically they are just dumped into one folder with no organization , like you might have in windows explorer folders and subfolders .  0\n",
              "4                                                                                                           i was using the cheapie pail ... and it worked ok until the opening device fell apart .  1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "pd.set_option('max_colwidth', 300)\n",
        "df_marked.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TQue8dKWC2z"
      },
      "source": [
        "Тексты уже приведены к нижнему регистру, проводить такую предобработку самим не нужно. Ожидаемо, в отзывах много речи от первого лица и эмоционально окрашенных слов и словосочетаний (\"fell in love\", \"perfect\", \"like\"). \n",
        "\n",
        "Размеченные данные будут использоваться для решения 3 подзадач:\n",
        "\n",
        "1. Обучение модели;\n",
        "2. Выбор гиперпараметров (посредством кросс-валидации);\n",
        "3. Оценка точности модели после подбора гиперпараметров.\n",
        "\n",
        "Для решения последней подзадачи выделим тестовую выборку. Предварительно продублируем отрицательные отзывы, чтобы выровнять классы (конечно, это не лучший способ выравнивания, но самый простой)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etW1xkI_0nWI",
        "outputId": "02c10e85-71ff-470d-d957-888a22d2e51c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1750,), (750,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df = df_marked.append(df_marked[df_marked.y == 0].sample(500, random_state=0))\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.text, df.y, test_size=0.3, shuffle=True, random_state=0)\n",
        "X_train.shape, X_test.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVzeLCVKwKey"
      },
      "source": [
        "## Наивный байесовский классификатор"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uWw9L1lt5uJH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDu_tpIA-KMu"
      },
      "source": [
        "Результат с параметрами по умолчанию:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA8KRRkA6CjR",
        "outputId": "aea445e2-03b5-448f-c69f-1380bad7b762"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Средняя точность: 80.29% Среднеквадратичное отклонение: 3.61%\n"
          ]
        }
      ],
      "source": [
        "nb_clf = Pipeline(\n",
        "    [(\"vectorizer\", CountVectorizer()),\n",
        "    (\"classifier\", ComplementNB())]\n",
        ")\n",
        "cv_result = cross_val_score(nb_clf, X_train, y_train, cv=5)\n",
        "print (\"Средняя точность: %0.2f%%\" % (100.*cv_result.mean()),\n",
        "       \"Среднеквадратичное отклонение: %0.2f%%\" % (100.*cv_result.std()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7qlLETlAujG"
      },
      "source": [
        "Подберём гиперпараметр $\\alpha$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhm9sd5fSNeh",
        "outputId": "2282a278-375d-4ebc-f4d8-2749805aa74c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: ExperimentalWarning:\n",
            "\n",
            "OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
            "\n",
            "\u001b[32m[I 2022-01-08 09:24:23,603]\u001b[0m A new study created in memory with name: no-name-0c847e02-6860-4cd1-b76e-8c6012269953\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 09:24:23,792]\u001b[0m Trial 0 finished with value: 0.8005714285714287 and parameters: {'classifier__alpha': 0.7467890812042345}. Best is trial 0 with value: 0.8005714285714287.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 09:24:23,987]\u001b[0m Trial 1 finished with value: 0.804 and parameters: {'classifier__alpha': 0.26511299739209526}. Best is trial 1 with value: 0.804.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 09:24:24,175]\u001b[0m Trial 2 finished with value: 0.7885714285714285 and parameters: {'classifier__alpha': 0.012949003743846998}. Best is trial 1 with value: 0.804.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 09:24:24,376]\u001b[0m Trial 3 finished with value: 0.7982857142857143 and parameters: {'classifier__alpha': 0.6303601289967387}. Best is trial 1 with value: 0.804.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 09:24:24,568]\u001b[0m Trial 4 finished with value: 0.8051428571428572 and parameters: {'classifier__alpha': 0.30904014339956676}. Best is trial 4 with value: 0.8051428571428572.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OptunaSearchCV(estimator=Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
              "                                         ('classifier', ComplementNB())]),\n",
              "               n_trials=5,\n",
              "               param_distributions={'classifier__alpha': UniformDistribution(high=1.0, low=0.0)})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "param_distributions = {\n",
        "    \"classifier__alpha\": optuna.distributions.UniformDistribution(0.0, 1.0)\n",
        "}\n",
        "optuna_search = optuna.integration.OptunaSearchCV(\n",
        "    nb_clf, param_distributions, n_trials=5, cv=5, \n",
        ")\n",
        "optuna_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w49ONMBNBuP3"
      },
      "source": [
        "Обучим модель на всей обучающей выборке с лучшим значением гиперпараметра и оценим точность на тестовой выборке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umr9l6JAozff",
        "outputId": "10918626-60ea-4138-8770-7f0faf987ee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.85       387\n",
            "           1       0.83      0.84      0.84       363\n",
            "\n",
            "    accuracy                           0.84       750\n",
            "   macro avg       0.84      0.84      0.84       750\n",
            "weighted avg       0.84      0.84      0.84       750\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "nb_clf = Pipeline(\n",
        "    [(\"vectorizer\", CountVectorizer()),\n",
        "    (\"classifier\", ComplementNB(alpha = optuna_search.best_params_['classifier__alpha']))]\n",
        ")\n",
        "nb_clf.fit(X_train, y_train)\n",
        "print(classification_report(y_test, nb_clf.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получили 84% правильных ответов. Точность и полнота имеют примерно ту же величину, значит применяемого метода балансировки достаточно."
      ],
      "metadata": {
        "id": "ZX9KhUlijVn3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSTPZWkIwitM"
      },
      "source": [
        "## Линейный классификатор с предобработкой текста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JuuY2xRvWC24"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxZd3YB1CkYC"
      },
      "source": [
        "Получим сначала результат классификации на сыром тексте, без предобработки, с параметрами по умолчанию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3eq5dRMC6U4",
        "outputId": "fd38db89-a2cb-4e77-833f-982c7863a787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Средняя точность: 79.54% Среднеквадратичное отклонение: 3.78%\n"
          ]
        }
      ],
      "source": [
        "lr_clf = Pipeline(\n",
        "    [(\"vectorizer\", TfidfVectorizer()),\n",
        "    (\"classifier\", LogisticRegression(solver='liblinear'))]\n",
        ")\n",
        "cv_result = cross_val_score(lr_clf, X_train, y_train, cv=5)\n",
        "print (\"Средняя точность: %0.2f%%\" % (100.*cv_result.mean()),\n",
        "       \"Среднеквадратичное отклонение: %0.2f%%\" % (100.*cv_result.std()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL5o2ZtlDDk9"
      },
      "source": [
        "Результат похуже, чем у наивного байесовского классификатора. Попробуем его улучшить."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLr7qOFvWC3E"
      },
      "source": [
        "### Подготовка к предобработке текста\n",
        "\n",
        "Хотелось бы решить как минимум две задачи:\n",
        "\n",
        "1. убрать ошибки токенизации;\n",
        "2. сделать нормализацию, т.е. привести слова к форме, в которой слова \"bad\", \"worse\" и \"worst\" или \"good\", \"better\" и \"best\" для модели были одним признаком.\n",
        "3. учесть словосочетания: n-граммы, а лучше и n-k-skip-граммы.\n",
        "\n",
        "Для нормализации можно воспользоваться двумя методами:\n",
        "\n",
        "1. стемминг - \"стрижка\" окончаний (применим PorterStemmer из NLTK);\n",
        "2. лемматизация - поиск основы с использованием грамматических правил и словарей (для этого нам больше подойдёт инструментарий Spacy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "n8esDXpmWC3F"
      },
      "outputs": [],
      "source": [
        "from nltk.stem.snowball import PorterStemmer\n",
        "\n",
        "# Создадим вспомогательный анализатор на основе стеммера Портера\n",
        "def porter_stemmer_analyzer(text):\n",
        "    stemmer = PorterStemmer()\n",
        "    analyzer = CountVectorizer().build_analyzer()\n",
        "    return (stemmer.stem(word) for word in analyzer(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KtMmaAtAWC3H"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Документация spaCy говорит, что коллекцию текстов лучше обрабатывать не по одному, а через метод pipe.\n",
        "# Чтоб не отходить от привычного стиля организации пайплайна, обернём такую обработку в собственный трансформер.\n",
        "import string\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "punctuations = string.punctuation\n",
        "\n",
        "from nltk.util import skipgrams\n",
        "\n",
        "class SpacyTransformer(TransformerMixin, BaseEstimator):\n",
        "    \"\"\"\n",
        "    Трансформер на основе Spacy\n",
        "    Выполняет токенизацию, лемматизацию текста,  построение n-грамм и n-k-skip-грамм.\n",
        "    Параметры:\n",
        "    check_stop_words - исключать ли стоп-слова (spaCy их определяет во время разбора текста);\n",
        "    save_prons - сохранять ли исходную форму для личных местомений: в сомнительных случаях нормальной формой spaCy считает служебное слово \"-PRON-\";\n",
        "    ngram_len - максимальная длина n-грамм;\n",
        "    skipgram_k - максимальная длина пропуска n-k-skip-грамм.\n",
        "    \"\"\"\n",
        "    def __init__(self, check_stop_words=False, save_prons=False, ngram_len=1, skipgram_k=1):\n",
        "        self.save_prons = save_prons\n",
        "        self.check_stop_words = check_stop_words\n",
        "        self.ngram_len = ngram_len\n",
        "        self.skipgram_k = skipgram_k\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        return [list(self.doc_tokens(doc)) for doc in nlp.pipe(X)]\n",
        "    \n",
        "    def doc_tokens(self, doc):\n",
        "        \"\"\"Генератор токенов с учётом n-k-skip-грамм.\"\"\"\n",
        "        unigrams = list(self.unigrams(doc))\n",
        "        for token in unigrams:\n",
        "            # Униграммы возвращаем как есть.\n",
        "            yield token\n",
        "\n",
        "        ngram_len = min(len(unigrams), self.ngram_len)\n",
        "        # Более длинные словосочетания формируем в цикле.\n",
        "        for n in range(2, ngram_len + 1):\n",
        "            for token in skipgrams(unigrams, n, self.skipgram_k):\n",
        "                yield \" \".join(token)\n",
        "\n",
        "    def unigrams(self, doc):\n",
        "        \"\"\"\n",
        "        Генератор токенов документа Spacy. Позволяет:\n",
        "        1. Отфильтровать токены,\n",
        "        2. Преобразовать их к нужной форме,\n",
        "        \"\"\"\n",
        "        for token in (token for token in doc if self.use_token(token)):\n",
        "            if self.save_prons and token.lemma_ == \"-PRON-\":\n",
        "                yield token.lower_\n",
        "            yield token.lemma_.lower().strip()\n",
        "    \n",
        "    def use_token(self, token):\n",
        "        \"\"\"Метод, определяющий, какие из токенов будут использованы.\"\"\"\n",
        "        return not (\n",
        "            self.check_stop_words and token.is_stop\n",
        "        ) and token.text not in punctuations\n",
        "\n",
        "# Чтобы векторизаторы SKlearn не делали лишнего, определим ничего не делающий токенизатор\n",
        "def do_nothing(something):\n",
        "    return something"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка\n",
        "pipeline_with_preprocessing = Pipeline([\n",
        "    (\"preprocessor\", SpacyTransformer(ngram_len = 3, skipgram_k = 1)),\n",
        "    (\"vectorizer\", CountVectorizer(tokenizer = do_nothing, preprocessor=do_nothing))\n",
        "])\n",
        "pipeline_with_preprocessing.fit_transform(X_train).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V30Rs0lp7Pn",
        "outputId": "da896b7f-5191-4785-b2ba-ef8820bfccf9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1750, 91362)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3TdyvNfWC22"
      },
      "source": [
        "### Подбор гиперпараметров с учётом предобработки\n",
        "\n",
        "Гиперпараметрами в этом разделе будут:\n",
        "\n",
        "* способ предобработки (стемминг или лемматизация);\n",
        "* максимальная длина словосочетаний;\n",
        "* способ векторизации (простой \"мешок слов\" и TF-IDF);\n",
        "* пороги вхождения слов по частоте их употребления в корпусе;\n",
        "* параметры регуляризации логистической регрессии."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuDh-EDarApu",
        "outputId": "90bc9f93-4a7f-4384-e8c3-a7a6285eabf5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hYGwMbTV-U5p"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "def svm_objective(trial):\n",
        "  steps = []\n",
        "\n",
        "  ngram_len = trial.suggest_int(\"ngram_len\", 1, 8)\n",
        "  check_stop_words = trial.suggest_categorical(\"check_stop_words\", [False, True])\n",
        "\n",
        "  # Параметры препроцессинга\n",
        "  normalization = trial.suggest_categorical(\"normalization\", [\"stemming\", \"lemmatization\"])\n",
        "  if(normalization == \"stemming\"):\n",
        "    stop_words = stopwords if check_stop_words else None\n",
        "  else:\n",
        "    save_prons = trial.suggest_categorical(\"save_prons\", [False, True])\n",
        "    skipgram_k = trial.suggest_int(\"skipgram_k\", 0, 8)\n",
        "    steps.append((\"preprocessor\", SpacyTransformer(\n",
        "        save_prons=save_prons, \n",
        "        check_stop_words=check_stop_words,\n",
        "        ngram_len=ngram_len, \n",
        "        skipgram_k=skipgram_k)))\n",
        "\n",
        "  # Параметры векторизации\n",
        "  vectorizer_name = trial.suggest_categorical(\"vectorizer_name\", [\"CountVectorizer\", \"TfidfVectorizer\"])\n",
        "  max_df = trial.suggest_float(\"max_df\", 0.7, 1.)\n",
        "  min_df = trial.suggest_float(\"min_df\", 0., 0.3)\n",
        "\n",
        "  if(normalization == \"stemming\" and vectorizer_name == \"CountVectorizer\"):\n",
        "    steps.append((\"vectorizer\", CountVectorizer(\n",
        "        analyzer=porter_stemmer_analyzer,\n",
        "        min_df=min_df, max_df=max_df, stop_words = stop_words,\n",
        "        ngram_range=(1, ngram_len))))\n",
        "  elif(normalization == \"stemming\"):\n",
        "    steps.append((\"vectorizer\", TfidfVectorizer(\n",
        "        analyzer=porter_stemmer_analyzer,\n",
        "        min_df=min_df, max_df=max_df, stop_words = stop_words,\n",
        "        ngram_range=(1, ngram_len))))\n",
        "  elif(normalization == \"CountVectorizer\"):\n",
        "    steps.append((\"vectorizer\", CountVectorizer(\n",
        "        tokenizer = do_nothing, preprocessor=do_nothing,\n",
        "        min_df=min_df, max_df=max_df)))\n",
        "  else:\n",
        "    steps.append((\"vectorizer\", TfidfVectorizer(\n",
        "        tokenizer = do_nothing, preprocessor=do_nothing,\n",
        "        min_df=min_df, max_df=max_df)))\n",
        "\n",
        "  # Параметры классификатора\n",
        "  svc_c = trial.suggest_float(\"svc_c\", 1e-10, 1e10, log=True)\n",
        "  steps.append((\"classifier\", LogisticRegression(C=svc_c, solver='liblinear')))\n",
        "\n",
        "  clf = Pipeline(steps)\n",
        "\n",
        "  # Некоторые комбинации параметров могут быть бессмысленными, отключим вывод предупреждений\n",
        "  warnings.filterwarnings(\"ignore\")\n",
        "  cv_result = cross_val_score(clf, X_train, y_train, cv=5)\n",
        "  warnings.filterwarnings(\"default\")\n",
        "\n",
        "  return cv_result.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8G8btMDDBOnK",
        "outputId": "14743fcb-dfe2-402f-d3d1-e9555b075ff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-01-08 06:23:02,534]\u001b[0m A new study created in memory with name: no-name-ff54e71a-cca7-4bf5-a91a-a91842c6bbde\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: ExperimentalWarning:\n",
            "\n",
            "enqueue_trial is experimental (supported from v1.2.0). The interface can change in the future.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/study/study.py:857: ExperimentalWarning:\n",
            "\n",
            "create_trial is experimental (supported from v2.0.0). The interface can change in the future.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/study/study.py:857: ExperimentalWarning:\n",
            "\n",
            "add_trial is experimental (supported from v2.0.0). The interface can change in the future.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: ExperimentalWarning:\n",
            "\n",
            "enqueue_trial is experimental (supported from v1.2.0). The interface can change in the future.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: ExperimentalWarning:\n",
            "\n",
            "enqueue_trial is experimental (supported from v1.2.0). The interface can change in the future.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: ExperimentalWarning:\n",
            "\n",
            "enqueue_trial is experimental (supported from v1.2.0). The interface can change in the future.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: ExperimentalWarning:\n",
            "\n",
            "enqueue_trial is experimental (supported from v1.2.0). The interface can change in the future.\n",
            "\n",
            "\u001b[32m[I 2022-01-08 06:23:24,846]\u001b[0m Trial 0 finished with value: 0.8268571428571428 and parameters: {'ngram_len': 3, 'check_stop_words': False, 'normalization': 'lemmatization', 'save_prons': False, 'skipgram_k': 1, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 1.0, 'min_df': 0.0, 'svc_c': 1.0}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:23:47,042]\u001b[0m Trial 1 finished with value: 0.8268571428571428 and parameters: {'ngram_len': 3, 'check_stop_words': False, 'normalization': 'lemmatization', 'save_prons': True, 'skipgram_k': 1, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 1.0, 'min_df': 0.0, 'svc_c': 1.0}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:24:08,160]\u001b[0m Trial 2 finished with value: 0.8062857142857144 and parameters: {'ngram_len': 3, 'check_stop_words': True, 'normalization': 'lemmatization', 'save_prons': False, 'skipgram_k': 1, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 1.0, 'min_df': 0.0, 'svc_c': 1.0}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:24:29,173]\u001b[0m Trial 3 finished with value: 0.8062857142857144 and parameters: {'ngram_len': 3, 'check_stop_words': True, 'normalization': 'lemmatization', 'save_prons': True, 'skipgram_k': 1, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 1.0, 'min_df': 0.0, 'svc_c': 1.0}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:24:32,842]\u001b[0m Trial 4 finished with value: 0.7942857142857143 and parameters: {'ngram_len': 3, 'check_stop_words': False, 'normalization': 'stemming', 'vectorizer_name': 'TfidfVectorizer', 'max_df': 1.0, 'min_df': 0.0, 'svc_c': 1.0}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:25:34,048]\u001b[0m Trial 5 finished with value: 0.5205714285714286 and parameters: {'ngram_len': 8, 'check_stop_words': True, 'normalization': 'lemmatization', 'save_prons': False, 'skipgram_k': 5, 'vectorizer_name': 'CountVectorizer', 'max_df': 0.8955890419048169, 'min_df': 0.05533039039410768, 'svc_c': 0.0004555050625422123}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:25:37,680]\u001b[0m Trial 6 finished with value: 0.5645714285714286 and parameters: {'ngram_len': 7, 'check_stop_words': False, 'normalization': 'stemming', 'vectorizer_name': 'CountVectorizer', 'max_df': 0.857891740917825, 'min_df': 0.14064015566224783, 'svc_c': 9.574691990712808e-05}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:25:41,303]\u001b[0m Trial 7 finished with value: 0.6114285714285714 and parameters: {'ngram_len': 3, 'check_stop_words': True, 'normalization': 'stemming', 'vectorizer_name': 'CountVectorizer', 'max_df': 0.7214839117752789, 'min_df': 0.10230910143298262, 'svc_c': 12162.53495689761}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:26:04,278]\u001b[0m Trial 8 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:26:07,919]\u001b[0m Trial 9 finished with value: 0.6028571428571429 and parameters: {'ngram_len': 2, 'check_stop_words': False, 'normalization': 'stemming', 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.9470398495819655, 'min_df': 0.08790771365819207, 'svc_c': 41335217.92538862}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:26:11,557]\u001b[0m Trial 10 finished with value: 0.6205714285714286 and parameters: {'ngram_len': 2, 'check_stop_words': True, 'normalization': 'stemming', 'vectorizer_name': 'CountVectorizer', 'max_df': 0.8402053813955421, 'min_df': 0.07343213339903333, 'svc_c': 11847.103904283962}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:28:21,870]\u001b[0m Trial 11 finished with value: 0.5205714285714286 and parameters: {'ngram_len': 5, 'check_stop_words': False, 'normalization': 'lemmatization', 'save_prons': False, 'skipgram_k': 8, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.7579065142426596, 'min_df': 0.2415306283794525, 'svc_c': 1.2319113888357894e-10}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:28:43,538]\u001b[0m Trial 12 finished with value: 0.5205714285714286 and parameters: {'ngram_len': 5, 'check_stop_words': False, 'normalization': 'lemmatization', 'save_prons': True, 'skipgram_k': 0, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.9222495353500634, 'min_df': 0.232852619462288, 'svc_c': 1.3284534704866654e-05}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:29:03,732]\u001b[0m Trial 13 finished with value: 0.6045714285714285 and parameters: {'ngram_len': 1, 'check_stop_words': False, 'normalization': 'lemmatization', 'save_prons': True, 'skipgram_k': 3, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.9510693166634331, 'min_df': 0.18066373983293968, 'svc_c': 19586.525053712285}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:29:31,152]\u001b[0m Trial 14 finished with value: 0.5205714285714286 and parameters: {'ngram_len': 4, 'check_stop_words': False, 'normalization': 'lemmatization', 'save_prons': False, 'skipgram_k': 3, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.8001527378361042, 'min_df': 0.29179136439294084, 'svc_c': 8.31582988167208e-08}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:30:03,243]\u001b[0m Trial 15 finished with value: 0.6954285714285714 and parameters: {'ngram_len': 6, 'check_stop_words': False, 'normalization': 'lemmatization', 'save_prons': True, 'skipgram_k': 2, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.9603171514751183, 'min_df': 0.040131958639389904, 'svc_c': 878.6955695170186}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:30:23,498]\u001b[0m Trial 16 finished with value: 0.6148571428571428 and parameters: {'ngram_len': 1, 'check_stop_words': False, 'normalization': 'lemmatization', 'save_prons': True, 'skipgram_k': 5, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.8938021040644157, 'min_df': 0.13387471914901622, 'svc_c': 5069343688.053185}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:30:44,896]\u001b[0m Trial 17 finished with value: 0.5714285714285714 and parameters: {'ngram_len': 4, 'check_stop_words': False, 'normalization': 'lemmatization', 'save_prons': False, 'skipgram_k': 0, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.9600660940375603, 'min_df': 0.04705800458656547, 'svc_c': 0.0056785950125220145}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:31:06,198]\u001b[0m Trial 18 finished with value: 0.7148571428571429 and parameters: {'ngram_len': 2, 'check_stop_words': False, 'normalization': 'lemmatization', 'save_prons': True, 'skipgram_k': 2, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.9077997554215929, 'min_df': 0.030895319146467183, 'svc_c': 97.93817120848917}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:34:48,527]\u001b[0m Trial 19 finished with value: 0.6051428571428572 and parameters: {'ngram_len': 6, 'check_stop_words': False, 'normalization': 'lemmatization', 'save_prons': False, 'skipgram_k': 7, 'vectorizer_name': 'CountVectorizer', 'max_df': 0.8558238461556141, 'min_df': 0.1792625930498101, 'svc_c': 1095663.4192331496}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:35:19,785]\u001b[0m Trial 20 finished with value: 0.6034285714285714 and parameters: {'ngram_len': 4, 'check_stop_words': False, 'normalization': 'lemmatization', 'save_prons': True, 'skipgram_k': 4, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.9740911118150557, 'min_df': 0.11103898806627832, 'svc_c': 0.015897003532244585}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:35:40,547]\u001b[0m Trial 21 finished with value: 0.72 and parameters: {'ngram_len': 2, 'check_stop_words': False, 'normalization': 'lemmatization', 'save_prons': False, 'skipgram_k': 1, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.923768854657528, 'min_df': 0.027184266656681905, 'svc_c': 21.592521059395228}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:36:01,473]\u001b[0m Trial 22 finished with value: 0.7891428571428571 and parameters: {'ngram_len': 3, 'check_stop_words': True, 'normalization': 'lemmatization', 'save_prons': False, 'skipgram_k': 1, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.9810693483221822, 'min_df': 0.0007129046037462237, 'svc_c': 0.3191123806053624}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:36:21,692]\u001b[0m Trial 23 finished with value: 0.5205714285714286 and parameters: {'ngram_len': 3, 'check_stop_words': True, 'normalization': 'lemmatization', 'save_prons': False, 'skipgram_k': 0, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.9957693740158398, 'min_df': 0.06572385958623772, 'svc_c': 3.222539420696939e-07}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:36:43,310]\u001b[0m Trial 24 finished with value: 0.6154285714285714 and parameters: {'ngram_len': 4, 'check_stop_words': True, 'normalization': 'lemmatization', 'save_prons': False, 'skipgram_k': 2, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.9358709500711279, 'min_df': 0.021371166112421968, 'svc_c': 0.03347021579408527}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:37:04,425]\u001b[0m Trial 25 finished with value: 0.6737142857142857 and parameters: {'ngram_len': 5, 'check_stop_words': True, 'normalization': 'lemmatization', 'save_prons': False, 'skipgram_k': 1, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.9655996055836381, 'min_df': 0.022711768351759615, 'svc_c': 34.69544525901008}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:37:24,682]\u001b[0m Trial 26 finished with value: 0.5319999999999999 and parameters: {'ngram_len': 2, 'check_stop_words': True, 'normalization': 'lemmatization', 'save_prons': False, 'skipgram_k': 3, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.8803690529652488, 'min_df': 0.07337409145357641, 'svc_c': 1.7371780087021498}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:37:28,316]\u001b[0m Trial 27 finished with value: 0.6554285714285715 and parameters: {'ngram_len': 1, 'check_stop_words': True, 'normalization': 'stemming', 'vectorizer_name': 'CountVectorizer', 'max_df': 0.8110673141718483, 'min_df': 0.017289000694757493, 'svc_c': 0.0008009716110063659}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:37:50,685]\u001b[0m Trial 28 finished with value: 0.5205714285714286 and parameters: {'ngram_len': 3, 'check_stop_words': False, 'normalization': 'lemmatization', 'save_prons': True, 'skipgram_k': 2, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.9800143216334396, 'min_df': 0.05731117771994724, 'svc_c': 2.1755304949046405e-06}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:38:06,944]\u001b[0m Trial 29 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:38:23,220]\u001b[0m Trial 30 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:38:39,694]\u001b[0m Trial 31 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:38:56,431]\u001b[0m Trial 32 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:39:12,721]\u001b[0m Trial 33 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:39:28,997]\u001b[0m Trial 34 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:39:45,467]\u001b[0m Trial 35 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:40:01,738]\u001b[0m Trial 36 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:40:18,019]\u001b[0m Trial 37 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:40:34,277]\u001b[0m Trial 38 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:40:50,741]\u001b[0m Trial 39 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:41:07,029]\u001b[0m Trial 40 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:41:23,319]\u001b[0m Trial 41 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:41:39,784]\u001b[0m Trial 42 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:41:56,073]\u001b[0m Trial 43 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:42:12,377]\u001b[0m Trial 44 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:42:28,661]\u001b[0m Trial 45 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:42:45,081]\u001b[0m Trial 46 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:43:01,779]\u001b[0m Trial 47 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:43:17,995]\u001b[0m Trial 48 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:43:34,481]\u001b[0m Trial 49 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:43:50,706]\u001b[0m Trial 50 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:44:06,933]\u001b[0m Trial 51 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:44:23,245]\u001b[0m Trial 52 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:44:39,864]\u001b[0m Trial 53 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:44:56,454]\u001b[0m Trial 54 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:45:12,766]\u001b[0m Trial 55 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:45:29,062]\u001b[0m Trial 56 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:45:45,537]\u001b[0m Trial 57 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:46:01,779]\u001b[0m Trial 58 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:46:18,054]\u001b[0m Trial 59 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:46:34,295]\u001b[0m Trial 60 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:46:50,744]\u001b[0m Trial 61 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:47:07,401]\u001b[0m Trial 62 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:47:23,701]\u001b[0m Trial 63 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:47:40,134]\u001b[0m Trial 64 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:47:56,422]\u001b[0m Trial 65 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:48:12,726]\u001b[0m Trial 66 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:48:28,975]\u001b[0m Trial 67 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:48:45,449]\u001b[0m Trial 68 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:49:01,755]\u001b[0m Trial 69 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:49:17,992]\u001b[0m Trial 70 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:49:34,443]\u001b[0m Trial 71 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:49:50,691]\u001b[0m Trial 72 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:50:06,951]\u001b[0m Trial 73 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:50:23,172]\u001b[0m Trial 74 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:50:39,632]\u001b[0m Trial 75 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:50:56,220]\u001b[0m Trial 76 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:51:12,461]\u001b[0m Trial 77 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:51:28,703]\u001b[0m Trial 78 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:51:45,135]\u001b[0m Trial 79 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:52:01,389]\u001b[0m Trial 80 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:52:17,676]\u001b[0m Trial 81 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:52:33,919]\u001b[0m Trial 82 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[33m[W 2022-01-08 06:52:50,356]\u001b[0m Trial 83 failed, because the objective function returned nan.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:53:10,703]\u001b[0m Trial 84 finished with value: 0.6194285714285714 and parameters: {'ngram_len': 4, 'check_stop_words': True, 'normalization': 'lemmatization', 'save_prons': False, 'skipgram_k': 0, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.9372965110628864, 'min_df': 0.04729238567375214, 'svc_c': 524509.1454935729}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:53:31,043]\u001b[0m Trial 85 finished with value: 0.7222857142857143 and parameters: {'ngram_len': 2, 'check_stop_words': True, 'normalization': 'lemmatization', 'save_prons': True, 'skipgram_k': 4, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.994824462662722, 'min_df': 0.007910686759016473, 'svc_c': 0.36242657884678864}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:53:52,556]\u001b[0m Trial 86 finished with value: 0.6040000000000001 and parameters: {'ngram_len': 3, 'check_stop_words': False, 'normalization': 'lemmatization', 'save_prons': False, 'skipgram_k': 1, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.9764698700920316, 'min_df': 0.1701031744635939, 'svc_c': 413.8610325048629}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:54:12,959]\u001b[0m Trial 87 finished with value: 0.7497142857142858 and parameters: {'ngram_len': 3, 'check_stop_words': True, 'normalization': 'lemmatization', 'save_prons': True, 'skipgram_k': 1, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.9932908028246663, 'min_df': 0.0038156727350945868, 'svc_c': 2.1028438726775356}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:54:34,409]\u001b[0m Trial 88 finished with value: 0.7234285714285715 and parameters: {'ngram_len': 4, 'check_stop_words': True, 'normalization': 'lemmatization', 'save_prons': True, 'skipgram_k': 1, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.9991398973461212, 'min_df': 0.0006205649066546581, 'svc_c': 0.16902099693869257}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:54:38,056]\u001b[0m Trial 89 finished with value: 0.5205714285714286 and parameters: {'ngram_len': 3, 'check_stop_words': True, 'normalization': 'stemming', 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.972357435952418, 'min_df': 0.03431104269178376, 'svc_c': 0.0007405805716226564}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:54:58,825]\u001b[0m Trial 90 finished with value: 0.6794285714285714 and parameters: {'ngram_len': 2, 'check_stop_words': True, 'normalization': 'lemmatization', 'save_prons': True, 'skipgram_k': 2, 'vectorizer_name': 'CountVectorizer', 'max_df': 0.999491765912957, 'min_df': 0.016858167898755983, 'svc_c': 3.3232981142423896}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:55:02,475]\u001b[0m Trial 91 finished with value: 0.5880000000000001 and parameters: {'ngram_len': 8, 'check_stop_words': True, 'normalization': 'stemming', 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.9363031873549112, 'min_df': 0.08665482312543774, 'svc_c': 0.007739259413946638}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:55:23,238]\u001b[0m Trial 92 finished with value: 0.5205714285714286 and parameters: {'ngram_len': 3, 'check_stop_words': False, 'normalization': 'lemmatization', 'save_prons': True, 'skipgram_k': 0, 'vectorizer_name': 'CountVectorizer', 'max_df': 0.951620177344152, 'min_df': 0.11393041296962447, 'svc_c': 6.348857862220482e-05}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:55:26,924]\u001b[0m Trial 93 finished with value: 0.6582857142857143 and parameters: {'ngram_len': 3, 'check_stop_words': True, 'normalization': 'stemming', 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.7120444887170403, 'min_df': 0.05514606239443583, 'svc_c': 4319.691588233047}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:56:01,021]\u001b[0m Trial 94 finished with value: 0.6142857142857143 and parameters: {'ngram_len': 5, 'check_stop_words': False, 'normalization': 'lemmatization', 'save_prons': True, 'skipgram_k': 3, 'vectorizer_name': 'CountVectorizer', 'max_df': 0.7536982345376213, 'min_df': 0.09045340584251803, 'svc_c': 15.844524728269404}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:56:04,684]\u001b[0m Trial 95 finished with value: 0.6857142857142857 and parameters: {'ngram_len': 2, 'check_stop_words': True, 'normalization': 'stemming', 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.9822831325485769, 'min_df': 0.03928694798291059, 'svc_c': 287443.1356421719}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:56:29,750]\u001b[0m Trial 96 finished with value: 0.5519999999999999 and parameters: {'ngram_len': 6, 'check_stop_words': False, 'normalization': 'lemmatization', 'save_prons': False, 'skipgram_k': 1, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.8805855752925967, 'min_df': 0.2085306178392551, 'svc_c': 0.17237429757471356}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:56:33,446]\u001b[0m Trial 97 finished with value: 0.7274285714285714 and parameters: {'ngram_len': 4, 'check_stop_words': False, 'normalization': 'stemming', 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.9840319473795104, 'min_df': 0.014033867850257684, 'svc_c': 513.0445776562735}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:56:37,086]\u001b[0m Trial 98 finished with value: 0.7297142857142856 and parameters: {'ngram_len': 2, 'check_stop_words': False, 'normalization': 'stemming', 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.962431366051737, 'min_df': 0.0029572325670648996, 'svc_c': 0.054343696413087644}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n",
            "\u001b[32m[I 2022-01-08 06:56:40,761]\u001b[0m Trial 99 finished with value: 0.5645714285714285 and parameters: {'ngram_len': 3, 'check_stop_words': False, 'normalization': 'stemming', 'vectorizer_name': 'TfidfVectorizer', 'max_df': 0.9492834597575137, 'min_df': 0.279910774169797, 'svc_c': 4.517847849345143}. Best is trial 0 with value: 0.8268571428571428.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры:  {'ngram_len': 3, 'check_stop_words': False, 'normalization': 'lemmatization', 'save_prons': False, 'skipgram_k': 1, 'vectorizer_name': 'TfidfVectorizer', 'max_df': 1.0, 'min_df': 0.0, 'svc_c': 1.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"a84574d7-d6bd-4dda-92d7-cf8f3fe195d3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"a84574d7-d6bd-4dda-92d7-cf8f3fe195d3\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'a84574d7-d6bd-4dda-92d7-cf8f3fe195d3',\n",
              "                        [{\"mode\": \"markers\", \"name\": \"Objective Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], \"y\": [0.8268571428571428, 0.8268571428571428, 0.8062857142857144, 0.8062857142857144, 0.7942857142857143, 0.5205714285714286, 0.5645714285714286, 0.6114285714285714, 0.6028571428571429, 0.6205714285714286, 0.5205714285714286, 0.5205714285714286, 0.6045714285714285, 0.5205714285714286, 0.6954285714285714, 0.6148571428571428, 0.5714285714285714, 0.7148571428571429, 0.6051428571428572, 0.6034285714285714, 0.72, 0.7891428571428571, 0.5205714285714286, 0.6154285714285714, 0.6737142857142857, 0.5319999999999999, 0.6554285714285715, 0.5205714285714286, 0.6194285714285714, 0.7222857142857143, 0.6040000000000001, 0.7497142857142858, 0.7234285714285715, 0.5205714285714286, 0.6794285714285714, 0.5880000000000001, 0.5205714285714286, 0.6582857142857143, 0.6142857142857143, 0.6857142857142857, 0.5519999999999999, 0.7274285714285714, 0.7297142857142856, 0.5645714285714285]}, {\"name\": \"Best Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], \"y\": [0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428, 0.8268571428571428]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Optimization History Plot\"}, \"xaxis\": {\"title\": {\"text\": \"#Trials\"}}, \"yaxis\": {\"title\": {\"text\": \"Objective Value\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a84574d7-d6bd-4dda-92d7-cf8f3fe195d3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from optuna.visualization import plot_optimization_history\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "\n",
        "# Проверим сначала очевидные комбинации\n",
        "study.enqueue_trial({\n",
        "    \"normalization\": \"lemmatization\",\n",
        "    \"save_prons\": False,\n",
        "    \"check_stop_words\": False,\n",
        "    \"vectorizer_name\": \"TfidfVectorizer\",\n",
        "    'max_df': 1.0, \n",
        "    'min_df': 0.0,\n",
        "    'ngram_len': 3,\n",
        "    'skipgram_k': 1,\n",
        "    'svc_c': 1.0\n",
        "})\n",
        "study.enqueue_trial({\n",
        "    \"normalization\": \"lemmatization\",\n",
        "    \"save_prons\": True,\n",
        "    \"check_stop_words\": False,\n",
        "    \"vectorizer_name\": \"TfidfVectorizer\",\n",
        "    'max_df': 1.0, \n",
        "    'min_df': 0.0,\n",
        "    'ngram_len': 3,\n",
        "    'skipgram_k': 1,\n",
        "    'svc_c': 1.0\n",
        "})\n",
        "study.enqueue_trial({\n",
        "    \"normalization\": \"lemmatization\",\n",
        "    \"save_prons\": False,\n",
        "    \"check_stop_words\": True,\n",
        "    \"vectorizer_name\": \"TfidfVectorizer\",\n",
        "    'max_df': 1.0, \n",
        "    'min_df': 0.0,\n",
        "    'ngram_len': 3,\n",
        "    'skipgram_k': 1,\n",
        "    'svc_c': 1.0\n",
        "})\n",
        "study.enqueue_trial({\n",
        "    \"normalization\": \"lemmatization\",\n",
        "    \"save_prons\": True,\n",
        "    \"check_stop_words\": True,\n",
        "    \"vectorizer_name\": \"TfidfVectorizer\",\n",
        "    'max_df': 1.0, \n",
        "    'min_df': 0.0,\n",
        "    'ngram_len': 3,\n",
        "    'skipgram_k': 1,\n",
        "    'svc_c': 1.0\n",
        "})\n",
        "study.enqueue_trial({\n",
        "    \"normalization\": \"stemming\",\n",
        "    \"vectorizer_name\": \"TfidfVectorizer\",\n",
        "    'max_df': 1.0, \n",
        "    'min_df': 0.0,\n",
        "    'ngram_len': 3,\n",
        "    'svc_c': 1.0\n",
        "})\n",
        "\n",
        "# А теперь запустим оптимизацию с учётом указанных выше точек\n",
        "study.optimize(svm_objective, n_trials=100)\n",
        "\n",
        "print(\"Лучшие параметры: \", study.best_params)\n",
        "plot_optimization_history(study)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Лучший вариант с лемматизацией\n",
        "lr_clf = Pipeline([\n",
        "    (\"preprocessor\", SpacyTransformer(\n",
        "        save_prons=False, \n",
        "        check_stop_words=False,\n",
        "        ngram_len=3, \n",
        "        skipgram_k=1)),\n",
        "    (\"vectorizer\", TfidfVectorizer(\n",
        "        tokenizer = do_nothing, preprocessor=do_nothing,\n",
        "        min_df=0.0, max_df=1.0)),\n",
        "    (\"classifier\", LogisticRegression(C=1.0, solver='liblinear'))\n",
        "])\n",
        "lr_clf.fit(X_train, y_train)\n",
        "print(classification_report(y_test, lr_clf.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNN-GpdD6hV5",
        "outputId": "00ee27ce-4191-4841-f075-b53cdf53abe7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.84      0.87       387\n",
            "           1       0.84      0.91      0.87       363\n",
            "\n",
            "    accuracy                           0.87       750\n",
            "   macro avg       0.87      0.87      0.87       750\n",
            "weighted avg       0.87      0.87      0.87       750\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Запишем текущий результат\n",
        "df_answer['y'] = lr_clf.predict(df_answer.text)\n",
        "df_answer[['Id','y']].to_csv('product-reviews-sentiment-analysis-lr.csv', index = False)\n"
      ],
      "metadata": {
        "id": "Y_KUtVYG8CAk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZkyPWndWC3Q"
      },
      "source": [
        "Результат обсуждаемой в разделе модели - 87% правильных ответов, что превосходит наивный байесовский классификатор. Однако на проверочных данных Kaggle результат меньше 80%, будем пробовать дальше."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTe8Pao0B7ig"
      },
      "source": [
        "## Логистическая регрессия с использованием векторных представлений слов;\n",
        "## Дообученная нейросетевая модель-трансформер на основе BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pgtb1gZOZp3k",
        "outputId": "319a35e3-284e-4edc-8cda-a3c0a5a1b289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Скачиваем словари\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi6TtiLsWC21"
      },
      "source": [
        "## Простейшая модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jG2cJmhWC3Z"
      },
      "source": [
        "Хотя ожидалось, что лучший результат будет показан моделью с сильной регуляризацией и использованием триграмм, это не оправдалось."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKGjlGDaWC3a"
      },
      "source": [
        "На этом остановимся. К сожалению, качественного скачка результата достичь не удалось, хотя +3.5% точности тоже не худший результат. Эксперименты с другими простыми моделями (линейными и байесовскими), которые не вошли в итоговый ноутбук, пока также не принесли успеха. На будущее стоит попробовать учесть векторные представления слов и взаимосвязи слов."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "wZACwezMY2jt"
      ],
      "name": "sentiment c6w3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "857deb1f30b3e03b92089aa4f28cf98b8d46d1a9c8b7c4d3d14250c912b4f5c9"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}